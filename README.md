# 第三屆機器學習百日馬拉松 3rd-ML100Days

## 一、機器學習概論
* Day001 資料介紹與評估資料
* Day002 機器學習概論
* Day003 機器學習 - 流程與步驟
* Day004 EDA / 讀取資料與分析流程
## 二、資料清理數據前處理
* Day005 如何新建一個 dataframe? 如何讀取其他資料? (非 csv 的資料)
* Day006 EDA: 欄位的資料類型介紹及處理
* Day007 特徵類型
* Day008 EDA資料分佈
* Day009 EDA: Outlier 及處理
* Day010 數值型特徵 - 去除離群值
* Day011 常用的數值取代：中位數與分位數連續數值標準化
* Day012 數值型特徵-補缺失值與標準化
* Day013 DataFrame operation Data frame merge/常用的 DataFrame 操作
* Day014 程式實作 EDA: correlation/相關係數簡介
* Day015 EDA from Correlation
* Day016 EDA: 不同數值範圍間的特徵如何檢視 / 繪圖與樣式Kernel Density Estimation (KDE)
* Day017 EDA: 把連續型變數離散化
* Day018 程式實作 把連續型變數離散化
* Day019 Subplots
* Day020 Heatmap & Grid-plot
* Day021 模型初體驗 Logistic Regression
## 三、資料科學特徵工程技術
* Day022 特徵工程簡介
* Day023 數值型特徵 - 去除偏態
* Day024 類別型特徵 - 基礎處理
* Day025 類別型特徵 - 均值編碼
* Day026 類別型特徵 - 其他進階處理
* Day027 時間型特徵
* Day028 特徵組合 - 數值與數值組合
* Day029 特徵組合 - 類別與數值組合
* Day030 特徵選擇
* Day031 特徵評估
* Day032 分類型特徵優化 - 葉編碼
## 四、機器學習基礎模型建立
* Day033 機器如何學習?
* Day034 訓練 / 測試集切分的概念
* Day035 Regression vs. Classification
* Day036 評估指標選定 / Evaluation Metrics
* Day037 regression model 介紹 - 線性迴歸 / 羅吉斯回歸
* Day038 regression model 程式碼撰寫
* Day039 regression model 介紹 - LASSO 回歸 / Ridge 回歸
* Day040 regression model 程式碼撰寫
* Day041 tree based model - 決策樹 (Decision Tree) 模型介紹
* Day042 tree based model - 決策樹程式碼撰寫
* Day043 tree based model - 隨機森林 (Random Forest) 介紹
* Day044 tree based model - 隨機森林程式碼撰寫
* Day045 tree based model - 梯度提升機 (Gradient Boosting Machine) 介紹
* Day046 tree based model - 梯度提升機程式碼撰寫
## 五、機器學習調整參數
* Day047 超參數調整與優化
* Day048 Kaggle 競賽平台介紹
* Day049 集成方法 : 混合泛化(Blending)
* Day050 集成方法 : 堆疊泛化(Stacking)
* Day051 Kaggle期中考 考ML與調參相關
* Day052 Kaggle期中考 考ML與調參相關
* Day053 Kaggle期中考 考ML與調參相關
## 六、非監督式機器學習
* Day054 clustering 1 非監督式機器學習簡介
* Day055 clustering 2 聚類算法
* Day056 K-means 觀察 : 使用輪廓分析
* Day057 clustering 3 階層分群算法
* Day058 階層分群法 觀察 : 使用 2D 樣版資料集
* Day059 dimension reduction 1 降維方法-主成份分析
* Day060 PCA 觀察 : 使用手寫辨識資料集
* Day061 dimension reduction 2 降維方法-T-SNE
* Day062 t-sne 觀察 : 分群與流形還原
## 七、深度學習理論與實作
* Day063 神經網路介紹
* Day064 深度學習體驗 : 模型調整與學習曲線
* Day065 深度學習體驗 : 啟動函數與正規化
## 八、初探深度學習使用Keras
* Day066 Keras 安裝與介紹
* Day067 Keras Dataset
* Day068 Keras Sequential API
* Day069 Keras Module API
* Day070 多層感知 Multi-layer Perception
* Day071 損失函數 Loss Function
* Day072 啟動函數 Activation Function
* Day073 梯度下降Gradient Descent
* Day074 Gradient Descent 數學原理
* Day075 BackPropagation
* Day076 優化器 Optimizers
* Day077 訓練神經網路的細節與技巧 - Validation and Overfit
* Day078 訓練神經網路前的注意事項
* Day079 訓練神經網路的細節與技巧 - Learning Rate Effect
* Day080 優化器與學習率的組合與比較
* Day081 訓練神經網路的細節與技巧 - Regularization
* Day082 訓練神經網路的細節與技巧 - Dropout
* Day083 訓練神經網路的細節與技巧 - Batch Normalization
* Day084 正規化/機移除/批次標準化的 組合與比較
* Day085 訓練神經網路的細節與技巧 - 使用 callbacks 函數做 earlystop
* Day086 訓練神經網路的細節與技巧 - 使用 callbacks 函數儲存 model
* Day087 訓練神經網路的細節與技巧 - 使用 callbacks 函數做 reduce learning rate
* Day088 訓練神經網路的細節與技巧 - 撰寫自己的 callbacks 函數
* Day089 訓練神經網路的細節與技巧 - 撰寫自己的 Loss Function
* Day090 使用傳統電腦視覺與機器學習進行影像辨識
* Day091 使用傳統電腦視覺與機器學習進行影像辨識
## 九、深度學習應用卷積神經網路
* Day092 卷積神經網路 (Convolution Neural Network, CNN) 簡介
* Day093 卷積神經網路架構細節
* Day094 卷積神經網路 - 卷積(Convolution)層與參數調整
* Day095 卷積神經網路 - 池化(Pooling)層與參數調整
* Day096 Keras 中的 CNN layers
* Day097 使用 CNN 完成 CIFAR-10 資料集
* Day098 訓練卷積神經網路的細節與技巧 - 處理大量數據
* Day099 訓練卷積神經網路的細節與技巧 - 處理小量數據
* Day100 訓練卷積神經網路的細節與技巧 - 轉移學習 (Transfer Learning)
## 十、Bonus進階補充
* Day104 互動式網頁神經網路視覺化
* Day105 CNN卷積網路回顧
* Day106 常見影像資料集介紹 (Cifar-10, ImageNet, COCO)
* Day107 電腦視覺應用介紹 - 影像分類, 影像分割, 物件偵測
